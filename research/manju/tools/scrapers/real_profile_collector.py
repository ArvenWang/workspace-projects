#!/usr/bin/env python3
"""
æ¼«å‰§æ•°æ®é‡‡é›† - ä½¿ç”¨çœŸå®Chrome Profileï¼ˆå·²ç™»å½•çŠ¶æ€ï¼‰
è·¯å¾„: ~/Library/Application Support/Google/Chrome/Default
"""

import asyncio
import json
import csv
from datetime import datetime
from pathlib import Path
from playwright.async_api import async_playwright


class RealProfileCollector:
    """ä½¿ç”¨çœŸå®Chrome Profileçš„é‡‡é›†å™¨"""
    
    def __init__(self):
        self.data_dir = Path(__file__).parent.parent.parent / "data" / "collected"
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.results = []
        
        # Chromeè·¯å¾„
        self.chrome_path = "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"
        self.user_data_dir = Path.home() / "Library/Application Support/Google/Chrome"
    
    async def __aenter__(self):
        self.playwright = await async_playwright().start()
        
        print("ğŸŒ å¯åŠ¨Chromeï¼ˆä½¿ç”¨ä½ çš„ç™»å½•çŠ¶æ€ï¼‰...")
        print(f"   Profileè·¯å¾„: {self.user_data_dir}")
        print("   è¿™å°†æ‰“å¼€ä½ æ—¥å¸¸ä½¿ç”¨çš„Chromeæµè§ˆå™¨")
        
        # ä½¿ç”¨çœŸå®Chrome Profile
        self.browser = await self.playwright.chromium.launch_persistent_context(
            user_data_dir=str(self.user_data_dir),
            headless=False,  # å¯è§æ¨¡å¼
            executable_path=self.chrome_path,
            args=['--profile-directory=Default'],
            viewport={'width': 1440, 'height': 900}
        )
        
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.browser.close()
        await self.playwright.stop()
    
    async def collect_xiaohongshu(self):
        """é‡‡é›†å°çº¢ä¹¦AIæ¼«å‰§æ•°æ®"""
        print("\n" + "="*60)
        print("ğŸ“• é‡‡é›†å°çº¢ä¹¦ - AIæ¼«å‰§æœç´¢")
        print("="*60)
        
        page = await self.browser.new_page()
        
        try:
            print("ğŸ” æœç´¢å…³é”®è¯: AIæ¼«å‰§")
            await page.goto('https://www.xiaohongshu.com/search_result/?keyword=AI%E6%BC%AB%E5%89%A7', 
                          wait_until='networkidle', timeout=60000)
            
            await page.wait_for_timeout(5000)
            
            # æ£€æŸ¥æ˜¯å¦å·²ç™»å½•
            login_check = await page.query_selector('.login-btn, .login-container')
            if login_check:
                print("âš ï¸  æ£€æµ‹åˆ°æœªç™»å½•ï¼Œè¯·æ‰‹åŠ¨ç™»å½•åç»§ç»­...")
                print("   ä½ æœ‰60ç§’æ—¶é—´å®Œæˆç™»å½•")
                await page.wait_for_timeout(60000)
            
            print("ğŸ“Š æå–ç¬”è®°æ•°æ®...")
            
            # æ»šåŠ¨åŠ è½½æ›´å¤š
            for i in range(5):
                await page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
                await page.wait_for_timeout(2000)
            
            # è·å–ç¬”è®°å¡ç‰‡
            notes = []
            cards = await page.query_selector_all('.note-item, [class*="note-item"], .feeds-page > div > div')
            print(f"   æ‰¾åˆ° {len(cards)} ä¸ªç¬”è®°")
            
            for idx, card in enumerate(cards[:50]):  # é‡‡é›†å‰50æ¡
                try:
                    # æå–æ ‡é¢˜
                    title_el = await card.query_selector('.title, h3, .content span, [class*="title"]')
                    title = await title_el.text_content() if title_el else ''
                    
                    # æå–ä½œè€…
                    author_el = await card.query_selector('.author, .user-name, [class*="author"]')
                    author = await author_el.text_content() if author_el else ''
                    
                    # æå–ç‚¹èµ
                    like_el = await card.query_selector('.like-count, .count, [class*="like"]')
                    likes = await like_el.text_content() if like_el else ''
                    
                    if title.strip() and len(title.strip()) > 3:
                        notes.append({
                            'rank': idx + 1,
                            'platform': 'å°çº¢ä¹¦',
                            'keyword': 'AIæ¼«å‰§',
                            'title': title.strip()[:100],
                            'author': author.strip()[:50] if author else '',
                            'likes': likes.strip() if likes else '',
                            'collected_at': datetime.now().isoformat()
                        })
                except Exception as e:
                    continue
            
            # æˆªå›¾
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            screenshot_path = self.data_dir / f"xiaohongshu_logged_in_{timestamp}.png"
            await page.screenshot(path=str(screenshot_path), full_page=True)
            
            result = {
                'platform': 'å°çº¢ä¹¦',
                'keyword': 'AIæ¼«å‰§',
                'url': page.url,
                'notes_count': len(notes),
                'notes': notes[:30],  # åªä¿å­˜å‰30æ¡è¯¦ç»†æ•°æ®
                'screenshot': str(screenshot_path),
                'collected_at': datetime.now().isoformat()
            }
            
            self.results.append(result)
            print(f"âœ… å°çº¢ä¹¦é‡‡é›†å®Œæˆ: {len(notes)} æ¡ç¬”è®°")
            
            # ä¿å­˜CSV
            if notes:
                csv_path = self.data_dir / f'xiaohongshu_ai_manju_{timestamp}.csv'
                with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
                    writer = csv.DictWriter(f, fieldnames=notes[0].keys())
                    writer.writeheader()
                    writer.writerows(notes)
                print(f"ğŸ’¾ CSVå·²ä¿å­˜: {csv_path}")
            
            await page.close()
            return result
            
        except Exception as e:
            print(f"âŒ å°çº¢ä¹¦é‡‡é›†å¤±è´¥: {str(e)}")
            await page.close()
            return {'platform': 'å°çº¢ä¹¦', 'error': str(e)}
    
    async def collect_bilibili(self):
        """é‡‡é›†Bç«™çŸ­å‰§æ•°æ®"""
        print("\n" + "="*60)
        print("ğŸ“º é‡‡é›†Bç«™ - çŸ­å‰§åˆ†åŒº")
        print("="*60)
        
        page = await self.browser.new_page()
        
        try:
            print("ğŸŒ è®¿é—®Bç«™çŸ­å‰§åˆ†åŒº...")
            await page.goto('https://www.bilibili.com/v/channel/shortplay',
                          wait_until='networkidle', timeout=60000)
            
            await page.wait_for_timeout(5000)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦éªŒè¯
            if 'éªŒè¯ç ' in await page.title():
                print("âš ï¸  é‡åˆ°éªŒè¯ç ï¼Œè¯·æ‰‹åŠ¨å®ŒæˆéªŒè¯...")
                print("   ä½ æœ‰60ç§’æ—¶é—´å®ŒæˆéªŒè¯")
                await page.wait_for_timeout(60000)
            
            print("ğŸ“Š æå–è§†é¢‘æ•°æ®...")
            
            # æ»šåŠ¨åŠ è½½
            for i in range(5):
                await page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
                await page.wait_for_timeout(2000)
            
            videos = []
            cards = await page.query_selector_all('.video-card, .bili-video-card, [class*="video-card"]')
            print(f"   æ‰¾åˆ° {len(cards)} ä¸ªè§†é¢‘")
            
            for idx, card in enumerate(cards[:50]):
                try:
                    title_el = await card.query_selector('h3, .title, a[title]')
                    title = await title_el.get_attribute('title') if title_el else ''
                    if not title:
                        title = await title_el.text_content() if title_el else ''
                    
                    play_el = await card.query_selector('.play-text, .view, [class*="play"]')
                    plays = await play_el.text_content() if play_el else ''
                    
                    author_el = await card.query_selector('.up-name, .author, [class*="up"]')
                    author = await author_el.text_content() if author_el else ''
                    
                    if title.strip():
                        videos.append({
                            'rank': idx + 1,
                            'platform': 'Bç«™',
                            'title': title.strip()[:100],
                            'author': author.strip()[:50] if author else '',
                            'plays': plays.strip() if plays else '',
                            'collected_at': datetime.now().isoformat()
                        })
                except:
                    continue
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            screenshot_path = self.data_dir / f"bilibili_shortplay_{timestamp}.png"
            await page.screenshot(path=str(screenshot_path), full_page=True)
            
            result = {
                'platform': 'Bç«™',
                'url': page.url,
                'videos_count': len(videos),
                'videos': videos[:30],
                'screenshot': str(screenshot_path),
                'collected_at': datetime.now().isoformat()
            }
            
            self.results.append(result)
            print(f"âœ… Bç«™é‡‡é›†å®Œæˆ: {len(videos)} ä¸ªè§†é¢‘")
            
            if videos:
                csv_path = self.data_dir / f'bilibili_shortplay_{timestamp}.csv'
                with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
                    writer = csv.DictWriter(f, fieldnames=videos[0].keys())
                    writer.writeheader()
                    writer.writerows(videos)
                print(f"ğŸ’¾ CSVå·²ä¿å­˜: {csv_path}")
            
            await page.close()
            return result
            
        except Exception as e:
            print(f"âŒ Bç«™é‡‡é›†å¤±è´¥: {str(e)}")
            await page.close()
            return {'platform': 'Bç«™', 'error': str(e)}
    
    async def collect_douyin(self):
        """é‡‡é›†æŠ–éŸ³çŸ­å‰§æ•°æ®"""
        print("\n" + "="*60)
        print("ğŸµ é‡‡é›†æŠ–éŸ³ - AIçŸ­å‰§")
        print("="*60)
        
        page = await self.browser.new_page()
        
        try:
            print("ğŸŒ è®¿é—®æŠ–éŸ³æœç´¢...")
            await page.goto('https://www.douyin.com/search/AI%E6%BC%AB%E5%89%A7',
                          wait_until='domcontentloaded', timeout=60000)
            
            await page.wait_for_timeout(8000)
            
            # æ£€æŸ¥éªŒè¯
            verify_check = await page.query_selector('.captcha, .verify, [class*="captcha"]')
            if verify_check:
                print("âš ï¸  é‡åˆ°éªŒè¯ï¼Œè¯·æ‰‹åŠ¨å®Œæˆ...")
                print("   ä½ æœ‰60ç§’æ—¶é—´å®ŒæˆéªŒè¯")
                await page.wait_for_timeout(60000)
            
            print("ğŸ“Š æå–è§†é¢‘æ•°æ®...")
            
            # æ»šåŠ¨åŠ è½½
            for i in range(5):
                await page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
                await page.wait_for_timeout(3000)
            
            videos = []
            cards = await page.query_selector_all('[class*="card"], [class*="item"], .search-card')
            print(f"   æ‰¾åˆ° {len(cards)} ä¸ªè§†é¢‘")
            
            for idx, card in enumerate(cards[:50]):
                try:
                    title_el = await card.query_selector('h3, .title, [class*="title"], [class*="desc"]')
                    title = await title_el.text_content() if title_el else ''
                    
                    like_el = await card.query_selector('[class*="like"], [class*="count"]')
                    likes = await like_el.text_content() if like_el else ''
                    
                    if title.strip() and len(title.strip()) > 5:
                        videos.append({
                            'rank': idx + 1,
                            'platform': 'æŠ–éŸ³',
                            'title': title.strip()[:100],
                            'likes': likes.strip()[:30] if likes else '',
                            'collected_at': datetime.now().isoformat()
                        })
                except:
                    continue
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            screenshot_path = self.data_dir / f"douyin_ai_manju_{timestamp}.png"
            await page.screenshot(path=str(screenshot_path), full_page=True)
            
            result = {
                'platform': 'æŠ–éŸ³',
                'url': page.url,
                'videos_count': len(videos),
                'videos': videos[:30],
                'screenshot': str(screenshot_path),
                'collected_at': datetime.now().isoformat()
            }
            
            self.results.append(result)
            print(f"âœ… æŠ–éŸ³é‡‡é›†å®Œæˆ: {len(videos)} ä¸ªè§†é¢‘")
            
            if videos:
                csv_path = self.data_dir / f'douyin_ai_manju_{timestamp}.csv'
                with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
                    writer = csv.DictWriter(f, fieldnames=videos[0].keys())
                    writer.writeheader()
                    writer.writerows(videos)
                print(f"ğŸ’¾ CSVå·²ä¿å­˜: {csv_path}")
            
            await page.close()
            return result
            
        except Exception as e:
            print(f"âŒ æŠ–éŸ³é‡‡é›†å¤±è´¥: {str(e)}")
            await page.close()
            return {'platform': 'æŠ–éŸ³', 'error': str(e)}
    
    def save_summary(self):
        """ä¿å­˜é‡‡é›†æ±‡æ€»"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        summary_path = self.data_dir / f"real_profile_collection_{timestamp}.json"
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜: {summary_path}")
        return summary_path


async def main():
    """ä¸»ç¨‹åº"""
    print("ğŸ¬ æ¼«å‰§æ•°æ®é‡‡é›†ç³»ç»Ÿ - çœŸå®Chrome Profile")
    print("="*60)
    print("âš ï¸  é‡è¦æç¤º:")
    print("   1. è¯·ç¡®ä¿Chromeå·²å®Œå…¨é€€å‡ºï¼ˆCmd+Qï¼‰")
    print("   2. è„šæœ¬ä¼šä½¿ç”¨ä½ çš„Chrome Profileï¼ˆå·²ç™»å½•çŠ¶æ€ï¼‰")
    print("   3. å¦‚æœçœ‹åˆ°éªŒè¯å¼¹çª—ï¼Œè¯·æ‰‹åŠ¨å®Œæˆ")
    print("   4. é‡‡é›†è¿‡ç¨‹ä¸­ä¸è¦æ“ä½œChrome")
    print("="*60)
    
    async with RealProfileCollector() as collector:
        # é‡‡é›†å„å¹³å°
        await collector.collect_xiaohongshu()
        await collector.collect_bilibili()
        await collector.collect_douyin()
        
        # ä¿å­˜æ±‡æ€»
        collector.save_summary()
    
    print("\n" + "="*60)
    print("âœ… é‡‡é›†å®Œæˆï¼")
    print("="*60)
    print(f"\nğŸ“ æ•°æ®ä¿å­˜ä½ç½®: {collector.data_dir}")


if __name__ == '__main__':
    asyncio.run(main())
