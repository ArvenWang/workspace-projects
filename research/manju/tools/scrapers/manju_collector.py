#!/usr/bin/env python3
"""
æ¼«å‰§Top500æ•°æ®é‡‡é›†ç³»ç»Ÿ
ä½¿ç”¨Playwrightè‡ªåŠ¨åŒ–çˆ¬å–å„å¹³å°çŸ­å‰§æ¦œå•æ•°æ®
"""

import asyncio
import json
import csv
from datetime import datetime
from pathlib import Path
from playwright.async_api import async_playwright


class ManjuDataCollector:
    """æ¼«å‰§æ•°æ®é‡‡é›†å™¨"""
    
    def __init__(self, headless=True):
        self.headless = headless
        self.data_dir = Path(__file__).parent.parent.parent / "data"
        self.raw_dir = self.data_dir / "raw"
        self.processed_dir = self.data_dir / "processed"
        self.rankings_dir = self.data_dir / "rankings"
        
        # åˆ›å»ºç›®å½•
        self.raw_dir.mkdir(parents=True, exist_ok=True)
        self.processed_dir.mkdir(parents=True, exist_ok=True)
        self.rankings_dir.mkdir(parents=True, exist_ok=True)
        
        self.results = []
    
    async def __aenter__(self):
        self.playwright = await async_playwright().start()
        self.browser = await self.playwright.chromium.launch(headless=self.headless)
        self.context = await self.browser.new_context(
            viewport={'width': 1920, 'height': 1080},
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.context.close()
        await self.browser.close()
        await self.playwright.stop()
    
    async def collect_douyin(self, limit=100):
        """é‡‡é›†æŠ–éŸ³çŸ­å‰§çƒ­æ¦œ"""
        print("ğŸ“± å¼€å§‹é‡‡é›†æŠ–éŸ³çŸ­å‰§çƒ­æ¦œ...")
        page = await self.context.new_page()
        
        try:
            # è®¿é—®æŠ–éŸ³çŸ­å‰§é¡µé¢
            await page.goto('https://www.douyin.com/', wait_until='networkidle', timeout=30000)
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            await page.wait_for_timeout(3000)
            
            # æœç´¢çŸ­å‰§ç›¸å…³å†…å®¹
            # æ³¨æ„ï¼šæŠ–éŸ³çš„åçˆ¬è¾ƒå¼ºï¼Œè¿™é‡Œä½¿ç”¨æœç´¢æ–¹å¼
            print("ğŸ” æ­£åœ¨æœç´¢çŸ­å‰§çƒ­æ¦œ...")
            
            # æˆªå›¾ä¿å­˜
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            screenshot_path = self.raw_dir / f"douyin_search_{timestamp}.png"
            await page.screenshot(path=str(screenshot_path), full_page=True)
            print(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: {screenshot_path}")
            
            # æå–é¡µé¢ä¿¡æ¯
            title = await page.title()
            url = page.url
            
            data = {
                'platform': 'douyin',
                'url': url,
                'title': title,
                'collected_at': datetime.now().isoformat(),
                'screenshot': str(screenshot_path),
                'notes': 'æŠ–éŸ³éœ€è¦ç™»å½•æ‰èƒ½æŸ¥çœ‹å®Œæ•´æ¦œå•ï¼Œå»ºè®®æ‰‹åŠ¨æ”¶é›†æˆ–ä½¿ç”¨API'
            }
            
            self.results.append(data)
            print(f"âœ… æŠ–éŸ³æ•°æ®é‡‡é›†å®Œæˆ")
            return data
            
        except Exception as e:
            print(f"âŒ æŠ–éŸ³é‡‡é›†å¤±è´¥: {str(e)}")
            return {'platform': 'douyin', 'error': str(e)}
        finally:
            await page.close()
    
    async def collect_kuaishou(self, limit=100):
        """é‡‡é›†å¿«æ‰‹çŸ­å‰§æ¦œå•"""
        print("ğŸ“± å¼€å§‹é‡‡é›†å¿«æ‰‹çŸ­å‰§æ¦œå•...")
        page = await self.context.new_page()
        
        try:
            # è®¿é—®å¿«æ‰‹
            await page.goto('https://www.kuaishou.com/', wait_until='networkidle', timeout=30000)
            await page.wait_for_timeout(3000)
            
            # æˆªå›¾ä¿å­˜
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            screenshot_path = self.raw_dir / f"kuaishou_{timestamp}.png"
            await page.screenshot(path=str(screenshot_path), full_page=True)
            
            title = await page.title()
            
            data = {
                'platform': 'kuaishou',
                'url': page.url,
                'title': title,
                'collected_at': datetime.now().isoformat(),
                'screenshot': str(screenshot_path),
                'notes': 'å¿«æ‰‹éœ€è¦ç™»å½•åæŸ¥çœ‹æ˜ŸèŠ’çŸ­å‰§æ¦œ'
            }
            
            self.results.append(data)
            print(f"âœ… å¿«æ‰‹æ•°æ®é‡‡é›†å®Œæˆ")
            return data
            
        except Exception as e:
            print(f"âŒ å¿«æ‰‹é‡‡é›†å¤±è´¥: {str(e)}")
            return {'platform': 'kuaishou', 'error': str(e)}
        finally:
            await page.close()
    
    async def collect_bilibili(self, limit=100):
        """é‡‡é›†Bç«™çŸ­å‰§æ•°æ®"""
        print("ğŸ“± å¼€å§‹é‡‡é›†Bç«™çŸ­å‰§æ•°æ®...")
        page = await self.context.new_page()
        
        try:
            # è®¿é—®Bç«™çŸ­å‰§åˆ†åŒº
            await page.goto('https://www.bilibili.com/v/channel/shortplay', wait_until='networkidle', timeout=30000)
            await page.wait_for_timeout(3000)
            
            # æå–çŸ­å‰§åˆ—è¡¨
            print("ğŸ” æå–çŸ­å‰§åˆ—è¡¨...")
            
            # è·å–è§†é¢‘å¡ç‰‡ä¿¡æ¯
            cards = await page.query_selector_all('.video-card, .video-list-item, .bili-video-card')
            
            videos = []
            for i, card in enumerate(cards[:limit]):
                try:
                    # æå–æ ‡é¢˜
                    title_el = await card.query_selector('a[title], .title, h3')
                    title = await title_el.get_attribute('title') if title_el else ''
                    if not title:
                        title = await title_el.text_content() if title_el else ''
                    
                    # æå–é“¾æ¥
                    link_el = await card.query_selector('a')
                    link = await link_el.get_attribute('href') if link_el else ''
                    
                    # æå–æ’­æ”¾é‡
                    play_el = await card.query_selector('.play-text, .view, .play-count')
                    play_count = await play_el.text_content() if play_el else ''
                    
                    # æå–ä½œè€…
                    author_el = await card.query_selector('.up-name, .author, .name')
                    author = await author_el.text_content() if author_el else ''
                    
                    videos.append({
                        'rank': i + 1,
                        'title': title.strip() if title else '',
                        'link': f"https:{link}" if link and link.startswith('//') else link,
                        'play_count': play_count.strip() if play_count else '',
                        'author': author.strip() if author else ''
                    })
                    
                except Exception as e:
                    continue
            
            # æˆªå›¾ä¿å­˜
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            screenshot_path = self.raw_dir / f"bilibili_{timestamp}.png"
            await page.screenshot(path=str(screenshot_path), full_page=True)
            
            data = {
                'platform': 'bilibili',
                'url': page.url,
                'title': await page.title(),
                'collected_at': datetime.now().isoformat(),
                'videos': videos,
                'video_count': len(videos),
                'screenshot': str(screenshot_path)
            }
            
            self.results.append(data)
            print(f"âœ… Bç«™é‡‡é›†å®Œæˆï¼Œè·å– {len(videos)} æ¡æ•°æ®")
            return data
            
        except Exception as e:
            print(f"âŒ Bç«™é‡‡é›†å¤±è´¥: {str(e)}")
            return {'platform': 'bilibili', 'error': str(e)}
        finally:
            await page.close()
    
    async def collect_3rd_party_reports(self):
        """é‡‡é›†ç¬¬ä¸‰æ–¹è¡Œä¸šæŠ¥å‘Š"""
        print("ğŸ“Š å¼€å§‹é‡‡é›†ç¬¬ä¸‰æ–¹è¡Œä¸šæŠ¥å‘Š...")
        
        # å¾·å¡”æ–‡ã€çŒ«çœ¼ã€äº‘åˆæ•°æ®ç­‰
        reports = [
            {'name': 'å¾·å¡”æ–‡çŸ­å‰§æŠ¥å‘Š', 'url': 'http://www.datawin.com.cn/', 'status': 'pending'},
            {'name': 'çŒ«çœ¼çŸ­å‰§æ•°æ®', 'url': 'https://piaofang.maoyan.com/', 'status': 'pending'},
        ]
        
        for report in reports:
            print(f"  - {report['name']}: {report['url']}")
        
        return {
            'platform': '3rd_party',
            'reports': reports,
            'notes': 'ç¬¬ä¸‰æ–¹æ•°æ®å¹³å°éœ€è¦æ³¨å†Œæˆ–ä»˜è´¹è·å–è¯¦ç»†æ•°æ®',
            'collected_at': datetime.now().isoformat()
        }
    
    def save_to_json(self, filename=None):
        """ä¿å­˜æ•°æ®ä¸ºJSON"""
        if not filename:
            filename = f"manju_collection_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        filepath = self.processed_dir / filename
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
        return filepath
    
    def save_to_csv(self, videos, filename=None):
        """ä¿å­˜è§†é¢‘åˆ—è¡¨ä¸ºCSV"""
        if not filename:
            filename = f"manju_videos_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        
        filepath = self.rankings_dir / filename
        
        if videos:
            keys = videos[0].keys()
            with open(filepath, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.DictWriter(f, fieldnames=keys)
                writer.writeheader()
                writer.writerows(videos)
            
            print(f"ğŸ’¾ CSVå·²ä¿å­˜åˆ°: {filepath}")
        
        return filepath


async def main():
    """ä¸»ç¨‹åº"""
    print("ğŸ¬ æ¼«å‰§Top500æ•°æ®é‡‡é›†ç³»ç»Ÿå¯åŠ¨\n")
    print("=" * 60)
    
    async with ManjuDataCollector(headless=False) as collector:
        # é‡‡é›†å„å¹³å°æ•°æ®
        # await collector.collect_douyin(limit=100)
        # await collector.collect_kuaishou(limit=100)
        
        # Bç«™çŸ­å‰§æ•°æ®
        bilibili_data = await collector.collect_bilibili(limit=50)
        
        # ç¬¬ä¸‰æ–¹æŠ¥å‘Š
        reports_data = await collector.collect_3rd_party_reports()
        collector.results.append(reports_data)
        
        # ä¿å­˜æ•°æ®
        collector.save_to_json()
        
        # å¦‚æœæœ‰Bç«™è§†é¢‘æ•°æ®ï¼Œä¿å­˜ä¸ºCSV
        if bilibili_data and 'videos' in bilibili_data:
            collector.save_to_csv(bilibili_data['videos'], 'bilibili_shortplay_ranking.csv')
    
    print("\n" + "=" * 60)
    print("âœ… æ•°æ®é‡‡é›†å®Œæˆï¼")


if __name__ == '__main__':
    asyncio.run(main())
