#!/usr/bin/env python3
"""
ç¬¬ä¸‰æ–¹æ•°æ®å¹³å°é‡‡é›†
è‰å¦ˆå¦ˆ / ç°è±šæ•°æ® / æ–°æ¦œ / é£ç“œæ•°æ®
"""

import asyncio
import json
import csv
from datetime import datetime
from pathlib import Path
from playwright.async_api import async_playwright


class ThirdPartyDataCollector:
    """ç¬¬ä¸‰æ–¹æ•°æ®å¹³å°é‡‡é›†å™¨"""
    
    def __init__(self):
        self.data_dir = Path(__file__).parent.parent.parent / "data" / "collected"
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.results = []
    
    async def __aenter__(self):
        self.playwright = await async_playwright().start()
        self.browser = await self.playwright.chromium.launch(
            headless=False,
            executable_path="/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.browser.close()
        await self.playwright.stop()
    
    async def collect_channmama(self):
        """é‡‡é›†è‰å¦ˆå¦ˆæ•°æ®"""
        print("\n" + "="*60)
        print("ğŸŒŸ é‡‡é›†è‰å¦ˆå¦ˆ - æŠ–éŸ³æ•°æ®")
        print("="*60)
        
        context = await self.browser.new_context(viewport={'width': 1440, 'height': 900})
        page = await context.new_page()
        
        try:
            print("ğŸŒ è®¿é—®è‰å¦ˆå¦ˆå®˜ç½‘...")
            await page.goto('https://www.chanmama.com/', wait_until='networkidle', timeout=60000)
            await page.wait_for_timeout(3000)
            
            # æ£€æŸ¥æ˜¯å¦å·²ç™»å½•
            if 'ç™»å½•' in await page.title() or await page.query_selector('.login'):
                print("âš ï¸  è‰å¦ˆå¦ˆéœ€è¦ç™»å½•")
                print("   è¯·åœ¨æµè§ˆå™¨ä¸­å®Œæˆç™»å½•ï¼Œç­‰å¾…20ç§’...")
                await page.wait_for_timeout(20000)
            
            # è®¿é—®çŸ­å‰§æ•°æ®é¡µé¢
            print("ğŸ” æœç´¢çŸ­å‰§ç›¸å…³æ•°æ®...")
            
            # å°è¯•è®¿é—®çƒ­é—¨è§†é¢‘æ¦œ
            await page.goto('https://www.chanmama.com/promotion/douyin/rank', timeout=60000)
            await page.wait_for_timeout(5000)
            
            screenshot_path = self.data_dir / f"channmama_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
            await page.screenshot(path=str(screenshot_path), full_page=True)
            
            print(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: {screenshot_path}")
            
            result = {
                'platform': 'è‰å¦ˆå¦ˆ',
                'url': page.url,
                'screenshot': str(screenshot_path),
                'collected_at': datetime.now().isoformat()
            }
            self.results.append(result)
            return result
            
        except Exception as e:
            print(f"âŒ è‰å¦ˆå¦ˆé‡‡é›†å¤±è´¥: {str(e)}")
            return {'platform': 'è‰å¦ˆå¦ˆ', 'error': str(e)}
        finally:
            await context.close()
    
    async def collect_huitun(self):
        """é‡‡é›†ç°è±šæ•°æ®"""
        print("\n" + "="*60)
        print("ğŸ‹ é‡‡é›†ç°è±šæ•°æ® - å°çº¢ä¹¦æ•°æ®")
        print("="*60)
        
        context = await self.browser.new_context(viewport={'width': 1440, 'height': 900})
        page = await context.new_page()
        
        try:
            print("ğŸŒ è®¿é—®ç°è±šæ•°æ®å®˜ç½‘...")
            await page.goto('https://www.huitun.com/', wait_until='networkidle', timeout=60000)
            await page.wait_for_timeout(3000)
            
            screenshot_path = self.data_dir / f"huitun_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
            await page.screenshot(path=str(screenshot_path), full_page=True)
            
            print(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: {screenshot_path}")
            
            result = {
                'platform': 'ç°è±šæ•°æ®',
                'url': page.url,
                'screenshot': str(screenshot_path),
                'collected_at': datetime.now().isoformat()
            }
            self.results.append(result)
            return result
            
        except Exception as e:
            print(f"âŒ ç°è±šæ•°æ®é‡‡é›†å¤±è´¥: {str(e)}")
            return {'platform': 'ç°è±šæ•°æ®', 'error': str(e)}
        finally:
            await context.close()
    
    async def collect_newrank(self):
        """é‡‡é›†æ–°æ¦œæ•°æ®"""
        print("\n" + "="*60)
        print("ğŸ“ˆ é‡‡é›†æ–°æ¦œæ•°æ® - å…¨å¹³å°")
        print("="*60)
        
        context = await self.browser.new_context(viewport={'width': 1440, 'height': 900})
        page = await context.new_page()
        
        try:
            print("ğŸŒ è®¿é—®æ–°æ¦œå®˜ç½‘...")
            await page.goto('https://www.newrank.cn/', wait_until='networkidle', timeout=60000)
            await page.wait_for_timeout(3000)
            
            # æ£€æŸ¥ç™»å½•çŠ¶æ€
            if 'ç™»å½•' in await page.title() or await page.query_selector('.login-btn'):
                print("âš ï¸  æ–°æ¦œéœ€è¦ç™»å½•")
                print("   è¯·åœ¨æµè§ˆå™¨ä¸­å®Œæˆç™»å½•ï¼Œç­‰å¾…20ç§’...")
                await page.wait_for_timeout(20000)
            
            # è®¿é—®çŸ­è§†é¢‘æ¦œå•
            print("ğŸ” è®¿é—®çŸ­è§†é¢‘æ¦œå•...")
            await page.goto('https://www.newrank.cn/public/info/list.html?period=day&dataType=shortvideo', timeout=60000)
            await page.wait_for_timeout(5000)
            
            # æå–æ•°æ®
            print("ğŸ“Š æå–æ¦œå•æ•°æ®...")
            rows = await page.query_selector_all('.rank-item, .list-item, tr')
            print(f"   æ‰¾åˆ° {len(rows)} æ¡æ•°æ®")
            
            data = []
            for idx, row in enumerate(rows[:20]):
                try:
                    cells = await row.query_selector_all('td, .cell, .item')
                    if len(cells) >= 3:
                        rank = await cells[0].text_content() if len(cells) > 0 else ''
                        title = await cells[1].text_content() if len(cells) > 1 else ''
                        author = await cells[2].text_content() if len(cells) > 2 else ''
                        
                        if title.strip():
                            data.append({
                                'rank': rank.strip() if rank else str(idx + 1),
                                'platform': 'æ–°æ¦œ',
                                'title': title.strip()[:100],
                                'author': author.strip()[:50] if author else '',
                                'collected_at': datetime.now().isoformat()
                            })
                except:
                    continue
            
            screenshot_path = self.data_dir / f"newrank_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
            await page.screenshot(path=str(screenshot_path), full_page=True)
            
            print(f"âœ… æ–°æ¦œé‡‡é›†å®Œæˆ: {len(data)} æ¡æ•°æ®")
            
            # ä¿å­˜CSV
            if data:
                csv_path = self.data_dir / 'newrank_shortvideo.csv'
                with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
                    writer = csv.DictWriter(f, fieldnames=data[0].keys())
                    writer.writeheader()
                    writer.writerows(data)
                print(f"ğŸ’¾ CSVå·²ä¿å­˜: {csv_path}")
            
            result = {
                'platform': 'æ–°æ¦œ',
                'url': page.url,
                'data_count': len(data),
                'data': data,
                'screenshot': str(screenshot_path),
                'collected_at': datetime.now().isoformat()
            }
            self.results.append(result)
            return result
            
        except Exception as e:
            print(f"âŒ æ–°æ¦œé‡‡é›†å¤±è´¥: {str(e)}")
            return {'platform': 'æ–°æ¦œ', 'error': str(e)}
        finally:
            await context.close()
    
    async def collect_feigua(self):
        """é‡‡é›†é£ç“œæ•°æ®"""
        print("\n" + "="*60)
        print("ğŸ‰ é‡‡é›†é£ç“œæ•°æ® - æŠ–éŸ³ç‰ˆ")
        print("="*60)
        
        context = await self.browser.new_context(viewport={'width': 1440, 'height': 900})
        page = await context.new_page()
        
        try:
            print("ğŸŒ è®¿é—®é£ç“œæ•°æ®å®˜ç½‘...")
            await page.goto('https://www.feigua.cn/', wait_until='networkidle', timeout=60000)
            await page.wait_for_timeout(3000)
            
            screenshot_path = self.data_dir / f"feigua_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
            await page.screenshot(path=str(screenshot_path), full_page=True)
            
            print(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: {screenshot_path}")
            
            result = {
                'platform': 'é£ç“œæ•°æ®',
                'url': page.url,
                'screenshot': str(screenshot_path),
                'collected_at': datetime.now().isoformat()
            }
            self.results.append(result)
            return result
            
        except Exception as e:
            print(f"âŒ é£ç“œæ•°æ®é‡‡é›†å¤±è´¥: {str(e)}")
            return {'platform': 'é£ç“œæ•°æ®', 'error': str(e)}
        finally:
            await context.close()
    
    def save_summary(self):
        """ä¿å­˜æ±‡æ€»"""
        summary_path = self.data_dir / f"third_party_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜: {summary_path}")


async def main():
    """ä¸»ç¨‹åº"""
    print("ğŸ¬ ç¬¬ä¸‰æ–¹æ•°æ®å¹³å°é‡‡é›†")
    print("="*60)
    print("âš ï¸  è¯·ç¡®ä¿å·²ç™»å½•å„æ•°æ®å¹³å°")
    print("   å¦‚æœæœªç™»å½•ï¼Œè¯·åœ¨æµè§ˆå™¨ä¸­å®Œæˆç™»å½•")
    print("="*60)
    
    async with ThirdPartyDataCollector() as collector:
        # é‡‡é›†å„å¹³å°
        await collector.collect_channmama()
        await collector.collect_huitun()
        await collector.collect_newrank()
        await collector.collect_feigua()
        
        # ä¿å­˜æ±‡æ€»
        collector.save_summary()
    
    print("\n" + "="*60)
    print("âœ… ç¬¬ä¸‰æ–¹æ•°æ®é‡‡é›†å®Œæˆï¼")
    print("="*60)


if __name__ == '__main__':
    asyncio.run(main())
