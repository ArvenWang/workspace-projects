#!/usr/bin/env python3
"""
æ¼«å‰§æ•°æ®åˆ†æžè„šæœ¬
åˆ†æžBç«™é‡‡é›†çš„æ¼«å‰§æ•°æ®
"""

import json
from collections import Counter
import re

DATA_FILE = '/Users/wangjingwen/.openclaw/workspace/research/manju/data/collected/bilibili_manju.json'
OUTPUT_FILE = '/Users/wangjingwen/.openclaw/workspace/research/manju/analysis/bilibili_manju_analysis.json'

def load_data():
    with open(DATA_FILE) as f:
        return json.load(f)

def analyze(data):
    # 1. åŸºæœ¬ç»Ÿè®¡
    total = len(data)
    total_plays = sum(int(item.get('play', 0)) for item in data)
    avg_plays = total_plays / total if total > 0 else 0
    
    # 2. æ’­æ”¾é‡åˆ†å¸ƒ
    play_distribution = {
        '100ä¸‡+': len([d for d in data if int(d.get('play', 0)) >= 1000000]),
        '50ä¸‡-100ä¸‡': len([d for d in data if 500000 <= int(d.get('play', 0)) < 1000000]),
        '10ä¸‡-50ä¸‡': len([d for d in data if 100000 <= int(d.get('play', 0)) < 500000]),
        '10ä¸‡ä»¥ä¸‹': len([d for d in data if int(d.get('play', 0)) < 100000]),
    }
    
    # 3. å…³é”®è¯åˆ†å¸ƒ
    keywords = [item.get('keyword', '') for item in data]
    keyword_dist = dict(Counter(keywords))
    
    # 4. é«˜æ’­æ”¾é‡Top20
    sorted_by_play = sorted(data, key=lambda x: int(x.get('play', 0)), reverse=True)
    top20 = [
        {
            'title': item['title'][:50],
            'play': item['play'],
            'author': item['author'],
            'keyword': item.get('keyword', '')
        }
        for item in sorted_by_play[:20]
    ]
    
    # 5. çƒ­é—¨åˆ›ä½œè€…
    authors = [item.get('author', '') for item in data]
    author_dist = dict(Counter(authors).most_common(10))
    
    # 6. æ ‡é¢˜å…³é”®è¯æå–
    all_titles = ' '.join([item.get('title', '') for item in data])
    title_keywords = re.findall(r'[\u4e00-\u9fa5]{2,4}', all_titles)
    title_keyword_dist = dict(Counter(title_keywords).most_common(30))
    
    return {
        'total': total,
        'total_plays': total_plays,
        'avg_plays': int(avg_plays),
        'play_distribution': play_distribution,
        'keyword_distribution': keyword_dist,
        'top20': top20,
        'top_authors': author_dist,
        'title_keywords': title_keyword_dist
    }

def main():
    print("ðŸ“Š åŠ è½½æ•°æ®...")
    data = load_data()
    
    print("ðŸ“ˆ åˆ†æžä¸­...")
    result = analyze(data)
    
    # ä¿å­˜ç»“æžœ
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    # æ‰“å°æ‘˜è¦
    print(f"\n{'='*50}")
    print(f"ðŸ“Š Bç«™æ¼«å‰§æ•°æ®åˆ†æžæŠ¥å‘Š")
    print(f"{'='*50}")
    print(f"æ€»æ•°æ®é‡: {result['total']}")
    print(f"æ€»æ’­æ”¾é‡: {result['total_plays']:,}")
    print(f"å¹³å‡æ’­æ”¾: {result['avg_plays']:,}")
    
    print(f"\nï¿½ï¿½ æ’­æ”¾é‡åˆ†å¸ƒ:")
    for k, v in result['play_distribution'].items():
        print(f"  {k}: {v}")
    
    print(f"\nðŸ”‘ æœç´¢å…³é”®è¯åˆ†å¸ƒ:")
    for k, v in sorted(result['keyword_distribution'].items(), key=lambda x: -x[1])[:10]:
        print(f"  {k}: {v}")
    
    print(f"\nðŸ† Top10 çƒ­é—¨:")
    for i, item in enumerate(result['top20'][:10], 1):
        print(f"  {i}. {item['title'][:35]} - {item['play']:,}")
    
    print(f"\nâœ… è¯¦ç»†åˆ†æžå·²ä¿å­˜åˆ°: {OUTPUT_FILE}")

if __name__ == '__main__':
    main()
