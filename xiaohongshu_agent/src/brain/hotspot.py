#!/usr/bin/env python3
"""
å°çº¢ä¹¦çƒ­ç‚¹åˆ†æå™¨
ä»å¤šæºè·å–çƒ­ç‚¹è¯é¢˜
"""

import requests
from datetime import datetime
from typing import List, Dict

class HotspotAnalyzer:
    """å¤šæºçƒ­ç‚¹è¯é¢˜è·å–"""
    
    def __init__(self, cache_ttl: int = 300):
        self.cache = {}
        self.cache_ttl = cache_ttl  # 5åˆ†é’Ÿç¼“å­˜
    
    def get_hot_topics(self) -> List[Dict]:
        """è·å–çƒ­ç‚¹è¯é¢˜"""
        if self._is_cache_valid("hot_topics"):
            return self.cache["hot_topics"]
        
        topics = []
        
        # 1. å¾®åšçƒ­æœ
        topics.extend(self._get_weibo_hot())
        
        # 2. çŸ¥ä¹çƒ­æ¦œ
        topics.extend(self._get_zhihu_hot())
        
        # 3. å°çº¢ä¹¦ç«™å†…çƒ­æœ
        topics.extend(self._get_xhs_hot())
        
        # 4. ç™¾åº¦çƒ­æœ
        topics.extend(self._get_baidu_hot())
        
        # ç¼“å­˜
        self.cache["hot_topics"] = topics
        self.cache["hot_topics_time"] = datetime.now().timestamp()
        
        return topics
    
    def _get_weibo_hot(self) -> List[Dict]:
        """è·å–å¾®åšçƒ­æœ"""
        try:
            url = "https://weibo.com/ajax/side/hotSearch"
            resp = requests.get(url, timeout=10)
            data = resp.json()
            
            if data.get("ok") == 1:
                realtime = data.get("data", {}).get("realtime", [])
                return [
                    {"platform": "weibo", "topic": item.get("word", ""), "raw": item}
                    for item in realtime[:10]
                ]
        except Exception as e:
            print(f"å¾®åšçƒ­æœè·å–å¤±è´¥: {e}")
        return []
    
    def _get_zhihu_hot(self) -> List[Dict]:
        """è·å–çŸ¥ä¹çƒ­æ¦œ"""
        try:
            url = "https://www.zhihu.com/api/v3/feed/topstory/hot-lists/total"
            headers = {"User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)"}
            resp = requests.get(url, headers=headers, timeout=10)
            data = resp.json()
            
            if data.get("data"):
                return [
                    {"platform": "zhihu", "topic": item.get("target", {}).get("title", ""), "raw": item}
                    for item in data["data"][:10]
                ]
        except Exception as e:
            print(f"çŸ¥ä¹çƒ­æ¦œè·å–å¤±è´¥: {e}")
        return []
    
    def _get_xhs_hot(self) -> List[Dict]:
        """è·å–å°çº¢ä¹¦ç«™å†…çƒ­æœ"""
        try:
            url = "https://edith.xiaohongshu.com/api/sns/web/v1/search/hot_words"
            resp = requests.get(url, timeout=10)
            data = resp.json()
            
            if data.get("data"):
                return [
                    {"platform": "xiaohongshu", "topic": item.get("word", ""), "raw": item}
                    for item in data["data"][:10]
                ]
        except Exception as e:
            print(f"å°çº¢ä¹¦çƒ­æœè·å–å¤±è´¥: {e}")
        return []
    
    def _get_baidu_hot(self) -> List[Dict]:
        """è·å–ç™¾åº¦çƒ­æœ"""
        try:
            url = "https://top.baidu.com/api"
            resp = requests.get(url, timeout=10)
            data = resp.json()
            
            if data.get("retcode") == 0:
                return [
                    {"platform": "baidu", "topic": item.get("word", ""), "raw": item}
                    for item in data.get("result", {}).get("data", [])[:10]
                ]
        except Exception as e:
            print(f"ç™¾åº¦çƒ­æœè·å–å¤±è´¥: {e}")
        return []
    
    def get_ai_related_topics(self) -> List[Dict]:
        """è·å–AI/ç§‘æŠ€ç›¸å…³çƒ­ç‚¹"""
        all_topics = self.get_hot_topics()
        
        ai_keywords = [
            "AI", "äººå·¥æ™ºèƒ½", "ChatGPT", "GPT", "å¤§æ¨¡å‹", "ç¼–ç¨‹", 
            "ç§‘æŠ€", "æŠ€æœ¯", "è½¯ä»¶", "ä»£ç ", "ç®—æ³•", "æœºå™¨äºº",
            "LLM", "AIGC", "OpenAI", "Claude", "Gemini"
        ]
        
        ai_topics = []
        for topic in all_topics:
            topic_text = topic.get("topic", "")
            if any(kw in topic_text for kw in ai_keywords):
                ai_topics.append(topic)
        
        return ai_topics[:5]
    
    def get_xhs_related_topics(self, keywords: List[str]) -> List[Dict]:
        """è·å–ä¸æŒ‡å®šå…³é”®è¯ç›¸å…³çš„å°çº¢ä¹¦çƒ­ç‚¹"""
        all_topics = self.get_hot_topics()
        related = []
        
        for topic in all_topics:
            topic_text = topic.get("topic", "")
            if any(kw in topic_text for kw in keywords):
                related.append(topic)
        
        return related[:5]
    
    def _is_cache_valid(self, key: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if key not in self.cache:
            return False
        cache_time = self.cache.get(f"{key}_time", 0)
        return (datetime.now().timestamp() - cache_time) < self.cache_ttl
    
    def clear_cache(self):
        """æ¸…é™¤ç¼“å­˜"""
        self.cache = {}


# æµ‹è¯•
if __name__ == "__main__":
    analyzer = HotspotAnalyzer()
    
    print("ğŸ”¥ çƒ­ç‚¹è¯é¢˜:")
    topics = analyzer.get_hot_topics()
    for i, t in enumerate(topics[:10], 1):
        print(f"  {i}. [{t['platform']}] {t['topic']}")
    
    print("\nğŸ¤– AIç›¸å…³çƒ­ç‚¹:")
    ai_topics = analyzer.get_ai_related_topics()
    for i, t in enumerate(ai_topics, 1):
        print(f"  {i}. {t['topic']}")
